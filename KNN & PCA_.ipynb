{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNtqLQJvdIRifZB51hS6qiI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["1. What is K-Nearest Neighbors (KNN) and how does it work in both\n","classification and regression problems?\n","\n","Ans:\n","\n","K-Nearest Neighbors (KNN):\n","A simple, non-parametric algorithm that predicts outcomes based on the ‘k’ closest training points.\n","\n","How it works:\n","\n","Choose k (number of neighbors).\n","\n","Compute distance to all training points (e.g., Euclidean).\n","\n","Select k nearest neighbors.\n","\n","Predict:\n","\n","Classification: majority class among neighbors.\n","\n","Regression: average value of neighbors.\n","\n","Pros: Simple, no assumptions, works for multi-class.\n","Cons: Slow on large data, sensitive to feature scale, struggles in high dimensions."],"metadata":{"id":"nrI2Of0J4F_e"}},{"cell_type":"markdown","source":["2. What is the Curse of Dimensionality and how does it affect KNN\n","performance?\n","\n","\n","Ans:\n","\n","Curse of Dimensionality:\n","\n","When the number of features (dimensions) in data increases, the data becomes sparse, distances between points become less meaningful, and patterns are harder to detect.\n","\n","Effect on KNN:\n","\n","KNN relies on distance to find neighbors.\n","\n","In high dimensions, all points may seem equally far, so KNN’s predictions become less accurate.\n","\n","Requires feature selection or dimensionality reduction to improve performance."],"metadata":{"id":"mfmfHn_K4XVC"}},{"cell_type":"markdown","source":["3.  What is Principal Component Analysis (PCA)? How is it different from\n","feature selection?\n","\n","Ans:\n","\n","Principal Component Analysis (PCA):\n","A dimensionality reduction technique that transforms original features into new uncorrelated components (principal components) capturing the most variance in the data.\n","\n","Difference from Feature Selection:\n","\n","PCA: Creates new features (linear combinations), reduces dimensions without dropping information.\n","\n","Feature Selection: Chooses a subset of original features, keeping them unchanged."],"metadata":{"id":"0BUQg5s84XRg"}},{"cell_type":"markdown","source":["4. What are eigenvalues and eigenvectors in PCA, and why are they\n","important?\n","\n","Ans:\n","\n","Eigenvectors and Eigenvalues in PCA:\n","\n","Eigenvectors: Directions of the new axes (principal components).\n","\n","Eigenvalues: Measure how much variance is along each eigenvector.\n","\n","Importance:\n","\n","Eigenvectors show the important directions in data.\n","\n","Eigenvalues tell us how much information/variance each component captures, helping to choose top components."],"metadata":{"id":"pWvPVaI44XOv"}},{"cell_type":"markdown","source":["5. How do KNN and PCA complement each other when applied in a single\n","pipeline?\n","\n","Ans:\n","\n","KNN + PCA pipeline:\n","\n","PCA reduces dimensions, removes noise, and keeps most important variance.\n","\n","KNN then finds neighbors in this lower-dimensional space.\n","\n","Benefit:\n","\n","Faster computation, less memory.\n","\n","Improved accuracy because distances are more meaningful."],"metadata":{"id":"qjUw3b2n4XKn"}},{"cell_type":"markdown","source":["6. Train a KNN Classifier on the Wine dataset with and without feature\n","scaling. Compare model accuracy in both cases.\n"],"metadata":{"id":"n_ZvDku-4XFh"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset\n","data = load_wine()\n","X, y = data.data, data.target\n","\n","# Split dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# --- KNN without scaling ---\n","knn1 = KNeighborsClassifier(n_neighbors=5)\n","knn1.fit(X_train, y_train)\n","y_pred1 = knn1.predict(X_test)\n","acc1 = accuracy_score(y_test, y_pred1)\n","\n","# --- KNN with scaling ---\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","knn2 = KNeighborsClassifier(n_neighbors=5)\n","knn2.fit(X_train_scaled, y_train)\n","y_pred2 = knn2.predict(X_test_scaled)\n","acc2 = accuracy_score(y_test, y_pred2)\n","\n","print(\"Accuracy without scaling:\", acc1)\n","print(\"Accuracy with scaling:\", acc2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-JmT28S42FB","executionInfo":{"status":"ok","timestamp":1770363581985,"user_tz":-330,"elapsed":2658,"user":{"displayName":"Vani Nagula","userId":"02342985426343673800"}},"outputId":"008c549f-df58-4b8f-c476-b66892c702a8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy without scaling: 0.7222222222222222\n","Accuracy with scaling: 0.9444444444444444\n"]}]},{"cell_type":"markdown","source":["7. Train a PCA model on the Wine dataset and print the explained variance\n","ratio of each principal component.\n"],"metadata":{"id":"EBPQ7iqj4XBk"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","\n","# Load dataset\n","data = load_wine()\n","X = data.data\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n","\n","# Train PCA\n","pca = PCA()\n","X_pca = pca.fit_transform(X_scaled)\n","\n","# Print explained variance ratio\n","print(\"Explained variance ratio of each PC:\")\n","for i, ratio in enumerate(pca.explained_variance_ratio_):\n","    print(f\"PC{i+1}: {ratio:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ygj9KEwg5LfS","executionInfo":{"status":"ok","timestamp":1770363606599,"user_tz":-330,"elapsed":481,"user":{"displayName":"Vani Nagula","userId":"02342985426343673800"}},"outputId":"f72fbf89-afe5-4324-fcf7-2b2ad914d33c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Explained variance ratio of each PC:\n","PC1: 0.3620\n","PC2: 0.1921\n","PC3: 0.1112\n","PC4: 0.0707\n","PC5: 0.0656\n","PC6: 0.0494\n","PC7: 0.0424\n","PC8: 0.0268\n","PC9: 0.0222\n","PC10: 0.0193\n","PC11: 0.0174\n","PC12: 0.0130\n","PC13: 0.0080\n"]}]},{"cell_type":"markdown","source":["8. Train a KNN Classifier on the PCA-transformed dataset (retain top 2\n","components). Compare the accuracy with the original dataset.\n"],"metadata":{"id":"1T3d3nYb4W9_"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset\n","data = load_wine()\n","X, y = data.data, data.target\n","\n","# Split dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# --- Scale features ---\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# --- KNN on original scaled data ---\n","knn_orig = KNeighborsClassifier(n_neighbors=5)\n","knn_orig.fit(X_train_scaled, y_train)\n","y_pred_orig = knn_orig.predict(X_test_scaled)\n","acc_orig = accuracy_score(y_test, y_pred_orig)\n","\n","# --- PCA (top 2 components) ---\n","pca = PCA(n_components=2)\n","X_train_pca = pca.fit_transform(X_train_scaled)\n","X_test_pca = pca.transform(X_test_scaled)\n","\n","# --- KNN on PCA-transformed data ---\n","knn_pca = KNeighborsClassifier(n_neighbors=5)\n","knn_pca.fit(X_train_pca, y_train)\n","y_pred_pca = knn_pca.predict(X_test_pca)\n","acc_pca = accuracy_score(y_test, y_pred_pca)\n","\n","print(\"Accuracy on original scaled data:\", acc_orig)\n","print(\"Accuracy on top-2 PCA data:\", acc_pca)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkwQ6v_V5TtQ","executionInfo":{"status":"ok","timestamp":1770363644283,"user_tz":-330,"elapsed":423,"user":{"displayName":"Vani Nagula","userId":"02342985426343673800"}},"outputId":"f76fa0d0-9e90-4a6d-8ae4-001a956f7f34"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on original scaled data: 0.9444444444444444\n","Accuracy on top-2 PCA data: 1.0\n"]}]},{"cell_type":"markdown","source":["9. Train a KNN Classifier with different distance metrics (euclidean,\n","manhattan) on the scaled Wine dataset and compare the results.\n"],"metadata":{"id":"Y6-FDwyi4W6Q"}},{"cell_type":"code","source":["from sklearn.datasets import load_wine\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","# Load dataset\n","data = load_wine()\n","X, y = data.data, data.target\n","\n","# Split dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# --- KNN with Euclidean distance ---\n","knn_euc = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n","knn_euc.fit(X_train_scaled, y_train)\n","y_pred_euc = knn_euc.predict(X_test_scaled)\n","acc_euc = accuracy_score(y_test, y_pred_euc)\n","\n","# --- KNN with Manhattan distance ---\n","knn_man = KNeighborsClassifier(n_neighbors=5, metric='manhattan')\n","knn_man.fit(X_train_scaled, y_train)\n","y_pred_man = knn_man.predict(X_test_scaled)\n","acc_man = accuracy_score(y_test, y_pred_man)\n","\n","print(\"Accuracy with Euclidean distance:\", acc_euc)\n","print(\"Accuracy with Manhattan distance:\", acc_man)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRU9Cfre4VLj","executionInfo":{"status":"ok","timestamp":1770363676452,"user_tz":-330,"elapsed":412,"user":{"displayName":"Vani Nagula","userId":"02342985426343673800"}},"outputId":"1d396dad-c16e-4f00-e182-4f96356a22f0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy with Euclidean distance: 0.9444444444444444\n","Accuracy with Manhattan distance: 0.9444444444444444\n"]}]}]}